{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2q5ilKDzS03s"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset\n",
        "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
      ],
      "metadata": {
        "id": "CRtRJ13lS6js"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the training and testing dataset \n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
      ],
      "metadata": {
        "id": "Sla8xF4KTeNy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split train into train and validation\n",
        "\n",
        "# number of validation samples - 10 % of the train samples\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "# number of test samples\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)"
      ],
      "metadata": {
        "id": "a8i_VsaZTmS6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    # possible values for the inputs are 0 to 255 - all elements will be between 0 and 1 \n",
        "    image /= 255.\n",
        "    return image, label\n",
        "\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "test_data = mnist_test.map(scale)"
      ],
      "metadata": {
        "id": "8D3f_gIiUE47"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
      ],
      "metadata": {
        "id": "GQNHPUu7UyLJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)"
      ],
      "metadata": {
        "id": "DWsXedfDUSAq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create bacthes for sgd\n",
        "BATCH_SIZE = 100\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ],
      "metadata": {
        "id": "NC_wz4AmVP_Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "\n",
        "\n",
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 50\n",
        "    \n",
        "# define model\n",
        "model = tf.keras.Sequential([\n",
        "    # each observation is 28x28x1 pixels, therefore it is a tensor of rank 3\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
        "])"
      ],
      "metadata": {
        "id": "UBwqYEDOVcSp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4ZaF6fwWV_yq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, epochs=10, validation_data=(validation_inputs, validation_targets), verbose =2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5I84_AqWDxK",
        "outputId": "b6c66cc1-b04d-4551-ed5c-e0ad0cfe9e09"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "540/540 - 9s - loss: 0.4251 - accuracy: 0.8803 - val_loss: 0.2224 - val_accuracy: 0.9378 - 9s/epoch - 16ms/step\n",
            "Epoch 2/10\n",
            "540/540 - 4s - loss: 0.1803 - accuracy: 0.9477 - val_loss: 0.1514 - val_accuracy: 0.9553 - 4s/epoch - 8ms/step\n",
            "Epoch 3/10\n",
            "540/540 - 4s - loss: 0.1346 - accuracy: 0.9607 - val_loss: 0.1275 - val_accuracy: 0.9622 - 4s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "540/540 - 4s - loss: 0.1096 - accuracy: 0.9671 - val_loss: 0.1092 - val_accuracy: 0.9678 - 4s/epoch - 8ms/step\n",
            "Epoch 5/10\n",
            "540/540 - 4s - loss: 0.0963 - accuracy: 0.9711 - val_loss: 0.0997 - val_accuracy: 0.9702 - 4s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "540/540 - 4s - loss: 0.0820 - accuracy: 0.9750 - val_loss: 0.0873 - val_accuracy: 0.9732 - 4s/epoch - 7ms/step\n",
            "Epoch 7/10\n",
            "540/540 - 4s - loss: 0.0736 - accuracy: 0.9779 - val_loss: 0.0742 - val_accuracy: 0.9780 - 4s/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "540/540 - 4s - loss: 0.0640 - accuracy: 0.9808 - val_loss: 0.0829 - val_accuracy: 0.9743 - 4s/epoch - 8ms/step\n",
            "Epoch 9/10\n",
            "540/540 - 4s - loss: 0.0574 - accuracy: 0.9829 - val_loss: 0.0655 - val_accuracy: 0.9783 - 4s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "540/540 - 4s - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.0600 - val_accuracy: 0.9822 - 4s/epoch - 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc67ef07110>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfVC8IqxWTWC",
        "outputId": "59849ffa-a08e-4f73-9298-95dc691db2e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.0929 - accuracy: 0.9726\n",
            "Test loss: 0.09. Test accuracy: 97.26%\n"
          ]
        }
      ]
    }
  ]
}